{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:15:35.141660Z",
     "start_time": "2020-01-15T08:15:35.137245Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:18:27.572051Z",
     "start_time": "2020-01-15T08:18:26.139003Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.join(os.getcwd().split('notebooks')[0], 'src'))\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use MNIST dataset to train the generator and the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:18:33.254840Z",
     "start_time": "2020-01-15T08:18:32.492903Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data from tf.keras.datasets\n",
    "(train_images, train_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# add a channel dimension\n",
    "train_images = train_images[:, :, :, np.newaxis]\n",
    "\n",
    "# normalize to [-1, 1]\n",
    "train_images = train_images / 255 - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow 2, use tf.data.Dataset object as the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:18:37.115230Z",
     "start_time": "2020-01-15T08:18:36.840983Z"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# batch and shuffle\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)  # from NumPy array\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level (`tf.keras.Sequential`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator generates **an image** from **a random seed**. It uses `tf.keras.layers.Conv2DTranspose` layers to upsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:18:38.801615Z",
     "start_time": "2020-01-15T08:18:38.791292Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        \n",
    "        # (100,) -> (7*7*256,)\n",
    "        layers.Dense(7*7*256, use_bias=False, input_shape=(100,)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        # (7*7*256,) -> (7, 7, 256)\n",
    "        layers.Reshape((7, 7, 256)),\n",
    "        \n",
    "        # (7, 7, 256 ) -> (7, 7, 128)\n",
    "        layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        # (7, 7, 128) -> (14, 14, 64)\n",
    "        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "        \n",
    "        # (14, 14, 64) -> (28, 28, 1)\n",
    "        layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        \n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:18:40.230085Z",
     "start_time": "2020-01-15T08:18:39.849498Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0a6017b128>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator is a CNN-based image **classifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:18:42.085214Z",
     "start_time": "2020-01-15T08:18:42.075925Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        \n",
    "        # (28, 28, 1) -> (14, 14, 64)\n",
    "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(28, 28, 1)),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # (14, 14, 64) -> (7, 7, 128)\n",
    "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # (7, 7, 128) -> (1,)\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1),\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T08:18:45.447511Z",
     "start_time": "2020-01-15T08:18:45.350932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00223909]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss and optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator loss quantifies how well the discriminator is able to distinguish real images from fakes. It compares:\n",
    "- the discriminator's **predictions on real images** to an array of **1s**.\n",
    "- the discriminator's **predictions on fake images** to an array of **0s**.\n",
    "\n",
    "\n",
    "Generator loss quantifies how well it was able to trick the discriminator. If the generator is performing well, the discriminator will classify the fake images as real (or 1). Here we compare the discriminator's **predictions on the fake images** to an array of **1s**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:12:52.456957Z",
     "start_time": "2020-01-14T04:12:52.450606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Binary cross-entropy loss as the base loss function\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T03:16:10.258527Z",
     "start_time": "2020-01-14T03:16:10.252109Z"
    }
   },
   "source": [
    "The discriminator and the generator optimizers are different since we will train two networks separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:12:55.402043Z",
     "start_time": "2020-01-14T04:12:55.398641Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create custom metrics to keep track of the loss and write them to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'logs/dcgan/' + current_time + '/train'\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "gen_metric = tf.keras.metrics.Mean('gen_loss', dtype=tf.float32)\n",
    "dis_metric = tf.keras.metrics.Mean('dis_loss', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorate the function to train one batch with `@tf.function` to run it in graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:55:23.015952Z",
     "start_time": "2020-01-14T04:55:22.969197Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_one_batch(images):\n",
    "    \n",
    "    # Create some random noise.\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
    "        \n",
    "        # Output of the generator\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        # Output of the discriminator\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        # Loss computation\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        dis_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "        # Metric recording\n",
    "        gen_metric(gen_loss)\n",
    "        dis_metric(dis_loss)\n",
    "        \n",
    "    # Gradients\n",
    "    gen_grad = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    dis_grad = dis_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    # Apply gradients\n",
    "    generator_optimizer.apply_gradients(zip(gen_grad, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(dis_grad, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:55:23.212915Z",
     "start_time": "2020-01-14T04:55:23.202079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Main training function.\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        # Train one step.\n",
    "        for image_batch in dataset:\n",
    "            train_one_batch(image_batch)\n",
    "        \n",
    "        # Write metrics to TensorBoard.\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('gen_loss', gen_metric.result(), step=epoch)\n",
    "            tf.summary.scalar('dis_loss', dis_metric.result(), step=epoch)\n",
    "        gen_metric.reset_states()\n",
    "        dis_metric.reset_states()\n",
    "        \n",
    "        # Produce images for the GIF\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, test_seed)\n",
    "        \n",
    "#         # Save the model every 15 epochs.\n",
    "#         if (epoch + 1) % 15 == 0:\n",
    "#             pass\n",
    "        \n",
    "        print(f'Time for epoch {epoch + 1} is {time.time() - start} sec')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, test_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:55:24.857891Z",
     "start_time": "2020-01-14T04:55:24.848752Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    \"\"\"Generate predictions and save as image\"\"\"\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(f'../data/final_data/dcgan/image_at_epoch_{epoch:04d}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:55:22.629285Z",
     "start_time": "2020-01-14T04:55:22.617500Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "n_examples_to_generate = 16\n",
    "\n",
    "# reuse the same seed overtime so it's easier to visualize progress\n",
    "test_seed = tf.random.normal([n_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:38:49.139801Z",
     "start_time": "2020-01-14T04:38:49.135118Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch):\n",
    "    return PIL.Image.open(f'../data/final_data/dcgan/image_at_epoch_{epoch:04d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:38:53.697798Z",
     "start_time": "2020-01-14T04:38:53.676480Z"
    }
   },
   "outputs": [],
   "source": [
    "display_image(132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:39:57.754018Z",
     "start_time": "2020-01-14T04:39:56.533963Z"
    }
   },
   "outputs": [],
   "source": [
    "anim_file = '../data/final_data/dcgan/dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('../data/final_data/dcgan/image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        frame = 2*(i**0.5)\n",
    "#         if round(frame) > round(last):\n",
    "#             last = frame\n",
    "#         else:\n",
    "#             continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
