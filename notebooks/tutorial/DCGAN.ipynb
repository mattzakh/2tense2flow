{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:15:24.119458Z",
     "start_time": "2020-01-31T03:15:24.114395Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:15:25.836655Z",
     "start_time": "2020-01-31T03:15:24.326144Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.join(os.getcwd().split('notebooks')[0], 'src'))\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use MNIST dataset to train the generator and the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:15:26.224816Z",
     "start_time": "2020-01-31T03:15:25.838157Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data from tf.keras.datasets\n",
    "(train_images, train_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# add a channel dimension\n",
    "train_images = train_images[:, :, :, np.newaxis]\n",
    "\n",
    "# normalize to [-1, 1]\n",
    "train_images = train_images / 255 - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorFlow 2, use tf.data.Dataset object as the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:16:26.392204Z",
     "start_time": "2020-01-31T03:16:26.145241Z"
    }
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 2000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# batch and shuffle\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)  # from NumPy array\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I'll use the Functional API, but you can use Sequential or model subclassing too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator generates **an image** from **a random seed**. It uses `tf.keras.layers.Conv2DTranspose` layers to upsample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:19:39.687686Z",
     "start_time": "2020-01-31T03:19:39.670338Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(100,))\n",
    "\n",
    "    # (100,) -> (7*7*256,)\n",
    "    x = tf.keras.layers.Dense(7*7*256, use_bias=False, input_shape=(100,))(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    # (7*7*256,) -> (7, 7, 256)\n",
    "    x = tf.keras.layers.Reshape((7, 7, 256))(x)\n",
    "\n",
    "    # (7, 7, 256 ) -> (7, 7, 128)\n",
    "    x = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    # (7, 7, 128) -> (14, 14, 64)\n",
    "    x = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "\n",
    "    # (14, 14, 64) -> (28, 28, 1)\n",
    "    outputs = tf.keras.layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='generator')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:19:31.241539Z",
     "start_time": "2020-01-31T03:19:29.774937Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator is a CNN-based image **classifier**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:22:31.057655Z",
     "start_time": "2020-01-31T03:22:31.045361Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "    # (28, 28, 1) -> (14, 14, 64)\n",
    "    x = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(28, 28, 1))(inputs)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    # (14, 14, 64) -> (7, 7, 128)\n",
    "    x = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "\n",
    "    # (7, 7, 128) -> (1,)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='discriminator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:22:31.801881Z",
     "start_time": "2020-01-31T03:22:31.527944Z"
    }
   },
   "outputs": [],
   "source": [
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define loss and optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator loss quantifies how well the discriminator is able to distinguish real images from fakes. It compares:\n",
    "- the discriminator's **predictions on real images** to an array of **1s**.\n",
    "- the discriminator's **predictions on fake images** to an array of **0s**.\n",
    "\n",
    "\n",
    "Generator loss quantifies how well it was able to trick the discriminator. If the generator is performing well, the discriminator will classify the fake images as real (or 1). Here we compare the discriminator's **predictions on the fake images** to an array of **1s**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:22:39.473683Z",
     "start_time": "2020-01-31T03:22:39.464740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Binary cross-entropy loss as the base loss function\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T03:16:10.258527Z",
     "start_time": "2020-01-14T03:16:10.252109Z"
    }
   },
   "source": [
    "The discriminator and the generator optimizers are different since we will train two networks separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:22:40.566806Z",
     "start_time": "2020-01-31T03:22:40.561459Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create custom metrics to keep track of the loss and write them to TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:22:42.150178Z",
     "start_time": "2020-01-31T03:22:42.126531Z"
    }
   },
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'logs/dcgan/' + current_time + '/train'\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "gen_metric = tf.keras.metrics.Mean('gen_loss', dtype=tf.float32)\n",
    "dis_metric = tf.keras.metrics.Mean('dis_loss', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decorate the function to train one batch with `@tf.function` to run it in graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:23:26.972933Z",
     "start_time": "2020-01-31T03:23:26.961184Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_one_batch(images):\n",
    "    \n",
    "    # Create some random noise.\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as dis_tape:\n",
    "        \n",
    "        # Output of the generator\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        # Output of the discriminator\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        # Loss computation\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        dis_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "        # Metric recording\n",
    "        gen_metric(gen_loss)\n",
    "        dis_metric(dis_loss)\n",
    "        \n",
    "    # Gradients\n",
    "    gen_grad = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    dis_grad = dis_tape.gradient(dis_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    # Apply gradients\n",
    "    generator_optimizer.apply_gradients(zip(gen_grad, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(dis_grad, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:23:28.023858Z",
     "start_time": "2020-01-31T03:23:28.013001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Main training function.\n",
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        \n",
    "        # Train one step.\n",
    "        for image_batch in dataset:\n",
    "            train_one_batch(image_batch)\n",
    "        \n",
    "        # Write metrics to TensorBoard.\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('gen_loss', gen_metric.result(), step=epoch)\n",
    "            tf.summary.scalar('dis_loss', dis_metric.result(), step=epoch)\n",
    "        gen_metric.reset_states()\n",
    "        dis_metric.reset_states()\n",
    "        \n",
    "        # Produce images for the GIF\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1, test_seed)\n",
    "        \n",
    "#         # Save the model every 15 epochs.\n",
    "#         if (epoch + 1) % 15 == 0:\n",
    "#             pass\n",
    "        \n",
    "        print(f'Time for epoch {epoch + 1} is {time.time() - start} sec')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, test_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:23:30.588094Z",
     "start_time": "2020-01-31T03:23:30.578092Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    \"\"\"Generate predictions and save as image\"\"\"\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig(f'../data/final_data/dcgan/image_at_epoch_{epoch:04d}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:23:31.490560Z",
     "start_time": "2020-01-31T03:23:31.477683Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "n_examples_to_generate = 16\n",
    "\n",
    "# reuse the same seed overtime so it's easier to visualize progress\n",
    "test_seed = tf.random.normal([n_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T03:54:11.451839Z",
     "start_time": "2020-01-31T03:45:16.057346Z"
    }
   },
   "outputs": [],
   "source": [
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create a GIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:38:49.139801Z",
     "start_time": "2020-01-14T04:38:49.135118Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Display a single image using the epoch number\n",
    "def display_image(epoch):\n",
    "    return PIL.Image.open(f'../data/final_data/dcgan/image_at_epoch_{epoch:04d}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:38:53.697798Z",
     "start_time": "2020-01-14T04:38:53.676480Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "display_image(132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T04:39:57.754018Z",
     "start_time": "2020-01-14T04:39:56.533963Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "anim_file = '../data/final_data/dcgan/dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('../data/final_data/dcgan/image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        frame = 2*(i**0.5)\n",
    "#         if round(frame) > round(last):\n",
    "#             last = frame\n",
    "#         else:\n",
    "#             continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
