{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:18:43.600685Z",
     "start_time": "2020-01-15T10:18:43.596924Z"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:18:46.093821Z",
     "start_time": "2020-01-15T10:18:43.997624Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A brief summary of major changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- API cleanup. Removes redundant APIs, makes APIs more consistent.\n",
    "- Eager execution. Decorate a Python function using `tf.function()` to mark it for JIT compilation.\n",
    "- No more \"globals\". If you lose track of a `tf.Variable`, it gets garbage collected.\n",
    "\n",
    "See https://www.tensorflow.org/guide/effective_tf2 for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T06:26:10.302192Z",
     "start_time": "2020-01-14T06:26:10.295684Z"
    }
   },
   "source": [
    "# Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use NumPy array or `tf.data` API for data pipelining. Generally, for larger dataset, you want your data as a `tf.data.Dataset` object. A Dataset object can be **created** from data in memory or disk, and can be **transformed** to another Dataset.\n",
    "\n",
    "See https://www.tensorflow.org/guide/data for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:18:48.314561Z",
     "start_time": "2020-01-15T10:18:47.935385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load MNIST data from `tf.keras.datasets`.\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()  # These are NumPy arrays.\n",
    "\n",
    "# Standardize data.\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Add a channel dimension.\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:18:48.906800Z",
     "start_time": "2020-01-15T10:18:48.316041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataset, then shuffle and batch them.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(1000).batch(32)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model architecture APIs (High-level to low-level):\n",
    "- Sequential model. Data goes through a sequence of layers.\n",
    "- Functional API. More flexible than Sequential model.\n",
    "- Layer subclassing. Subclass `tf.keras.layers.Layer` to create custom layer (custom computation blocks).\n",
    "- Model subclassing. Subclass `tf.keras.Model` to create custom model (custom training, evaluation, and prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T08:49:08.526875Z",
     "start_time": "2020-01-14T08:49:08.440872Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "], name='mnist_sequential')\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T08:49:09.396035Z",
     "start_time": "2020-01-14T08:49:09.388583Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T08:49:10.877569Z",
     "start_time": "2020-01-14T08:49:10.872903Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train from NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T08:41:13.249057Z",
     "start_time": "2020-01-14T08:40:48.001560Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test), callbacks=callbacks)\n",
    "print(f'Time taken : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Train from `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T08:49:50.599812Z",
     "start_time": "2020-01-14T08:49:12.781457Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(train_dataset, epochs=5, validation_data=test_dataset)\n",
    "print(f'Time taken : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T08:21:10.516702Z",
     "start_time": "2020-01-14T08:21:09.739796Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T08:21:11.698332Z",
     "start_time": "2020-01-14T08:21:11.071343Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T10:19:40.662480Z",
     "start_time": "2020-01-14T10:19:40.568869Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist_functional')\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T10:19:40.786314Z",
     "start_time": "2020-01-14T10:19:40.778500Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T10:20:21.520070Z",
     "start_time": "2020-01-14T10:19:41.314253Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(train_dataset, epochs=5, validation_data=test_dataset)\n",
    "print(f'Time taken : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Non-sequential example : ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T10:16:40.443743Z",
     "start_time": "2020-01-14T10:16:40.336978Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "x = tf.keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "block_1_output = tf.keras.layers.MaxPooling2D(3)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(block_1_output)\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.add([x, block_1_output])\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='resnet_functional')\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T10:17:53.292104Z",
     "start_time": "2020-01-14T10:17:53.283485Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-14T10:17:53.280965Z",
     "start_time": "2020-01-14T10:16:49.547734Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(train_dataset, epochs=5, validation_data=test_dataset)\n",
    "print(f'Time taken : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom \"layer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:18:50.534087Z",
     "start_time": "2020-01-15T10:18:50.525734Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()  # Initialize base class.\n",
    "        self.conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x += inputs\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Now it can be sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T06:08:03.121863Z",
     "start_time": "2020-01-15T06:08:03.013994Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(3),\n",
    "    ResidualBlock(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    \n",
    "], name='custom_layer_sequential')\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T06:08:03.193120Z",
     "start_time": "2020-01-15T06:08:03.184547Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T06:15:22.261615Z",
     "start_time": "2020-01-15T06:15:22.157727Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
    "x = tf.keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(3)(x)\n",
    "\n",
    "x = ResidualBlock()(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='custom_layer_functional')\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T06:15:22.465348Z",
     "start_time": "2020-01-15T06:15:22.459667Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:26:18.666837Z",
     "start_time": "2020-01-15T10:26:18.649131Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()  # Initialize base class.\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.pool = tf.keras.layers.MaxPooling2D(3)\n",
    "        self.residual = ResidualBlock()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(10, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.residual(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = CustomModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T09:20:33.416038Z",
     "start_time": "2020-01-15T09:20:33.410732Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T09:20:28.025770Z",
     "start_time": "2020-01-15T09:19:00.870642Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(train_dataset, epochs=5, validation_data=test_dataset)\n",
    "print(f'Time taken : {time.time() - start} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training APIs (High-level to low-level):\n",
    "- Built-in training loops. (`model.compile(...)`, then `model.fit(...)`).\n",
    "- Writing training loops from scratch with `tf.GradientTape`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to train and test one batch. Note that we're decorating the functions with `tf.function` to mark them for JIT compilations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:18:58.606303Z",
     "start_time": "2020-01-15T10:18:58.595889Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_on_batch(x, y):\n",
    "    \"\"\"Train one batch of (x, y)\"\"\"\n",
    "    # Compute loss while recording the gradient.\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x)\n",
    "        loss_value = loss(y, y_pred)\n",
    "        \n",
    "    # Get gradient of weights w.r.t. loss.\n",
    "    grad = tape.gradient(loss_value, model.trainable_weights)\n",
    "    # Using optimizer, apply gradients to trainable weights.\n",
    "    optimizer.apply_gradients(zip(grad, model.trainable_weights))\n",
    "    \n",
    "    # Compute metrics. Metrics will accumulate values.\n",
    "    for metric in metrics:\n",
    "        metric(y, y_pred)\n",
    "        \n",
    "    # Record loss\n",
    "    loss_metric(loss_value)\n",
    "        \n",
    "@tf.function\n",
    "def test_on_batch(x, y):\n",
    "    \"\"\"Test one batch of (x, y)\"\"\"\n",
    "    # Compute loss.\n",
    "    y_pred = model(x)\n",
    "    loss_value = loss(y, y_pred)\n",
    "    \n",
    "    # Compute metrics. Metrics will accumulate values.\n",
    "    for metric in metrics:\n",
    "        metric(y, y_pred)\n",
    "        \n",
    "    # Record loss\n",
    "    loss_metric(loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a function to perform the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:18:59.664230Z",
     "start_time": "2020-01-15T10:18:59.589736Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(train_data, epochs, validation_data=None):\n",
    "    \"\"\"Perform training loop.\"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        message = f'Epoch {epoch}/{epochs}'\n",
    "        \n",
    "        # Iterate through training dataset and\n",
    "        # train model on each batch.\n",
    "        for i, (x, y) in enumerate(train_data):\n",
    "            train_on_batch(x, y)\n",
    "            \n",
    "        # Obtain metric values after trained on all batches.\n",
    "        train_metric_values = {metric.name: metric.result().numpy() for metric in metrics}\n",
    "        train_loss_values = {'loss': loss_metric.result().numpy()}\n",
    "        # Reset metric states at the end of each epoch.\n",
    "        for metric in metrics:\n",
    "            metric.reset_states()\n",
    "        loss_metric.reset_states()\n",
    "        \n",
    "        message += ' - ' + ' - '.join([f'{k}: {v:.4f}' for k,v in train_loss_values.items()])\n",
    "        message += ' - ' + ' - '.join([f'{k}: {v:.4f}' for k,v in train_metric_values.items()])\n",
    "        \n",
    "        if validation_data is not None:\n",
    "            \n",
    "            # Iterate through validation dataset and\n",
    "            # train model on each batch.\n",
    "            for i, (x, y) in enumerate(validation_data):\n",
    "                test_on_batch(x, y)\n",
    "\n",
    "            # Obtain metric values after trained on all batches.\n",
    "            val_metric_values = {f'val_{metric.name}': metric.result().numpy() for metric in metrics}\n",
    "            val_loss_values = {'val_loss': loss_metric.result().numpy()}\n",
    "            # Reset metric states at the end of each epoch.\n",
    "            for metric in metrics:\n",
    "                metric.reset_states()\n",
    "            loss_metric.reset_states()\n",
    "                \n",
    "            message += ' - ' + ' - '.join([f'{k}: {v:.4f}' for k,v in val_loss_values.items()])\n",
    "            message += ' - ' + ' - '.join([f'{k}: {v:.4f}' for k,v in val_metric_values.items()])\n",
    "            \n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:26:20.549116Z",
     "start_time": "2020-01-15T10:26:20.529497Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_metric = tf.keras.metrics.Mean('loss')\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:25:18.073662Z",
     "start_time": "2020-01-15T10:25:18.056425Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "build() missing 1 required positional argument: 'input_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2f52417d930d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: build() missing 1 required positional argument: 'input_shape'"
     ]
    }
   ],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-15T10:20:07.635911Z",
     "start_time": "2020-01-15T10:19:32.645766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/5 - loss: 0.0716 - sparse_categorical_accuracy: 0.9785 - val_loss: 0.0371 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 1/5 - loss: 0.0355 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.0342 - val_sparse_categorical_accuracy: 0.9879\n",
      "Epoch 2/5 - loss: 0.0272 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0446 - val_sparse_categorical_accuracy: 0.9865\n",
      "Epoch 3/5 - loss: 0.0214 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.0375 - val_sparse_categorical_accuracy: 0.9879\n",
      "Epoch 4/5 - loss: 0.0182 - sparse_categorical_accuracy: 0.9949 - val_loss: 0.0278 - val_sparse_categorical_accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "# train(train_dataset.take(30), epochs=5, validation_data=test_dataset.take(30))\n",
    "train(train_dataset, epochs=5, validation_data=test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
